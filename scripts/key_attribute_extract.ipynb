{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import caffe\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import mxnet as mx\n",
    "from mxnet import image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 8\n",
    "\n",
    "model_stage1 = '../models/FLD_full/stage1.prototxt'\n",
    "assert(os.path.exists(model_stage1))\n",
    "weights_stage1 = '../models/FLD_full/FLD_full_models/stage1.caffemodel'\n",
    "assert(os.path.exists(weights_stage1))\n",
    "\n",
    "model_stage2 = '../models/FLD_full/cascade.prototxt'\n",
    "assert(os.path.exists(model_stage2))\n",
    "weights_stage2 = '../models/FLD_full/FLD_full_models/stage2.caffemodel'\n",
    "assert(os.path.exists(weights_stage2))\n",
    "\n",
    "model_stage3 = '../models/FLD_full/cascade.prototxt'\n",
    "assert(os.path.exists(model_stage3))\n",
    "weights_stage3_easy = '../models/FLD_full/FLD_full_models/stage3_easy.caffemodel'\n",
    "assert(os.path.exists(weights_stage3_easy))\n",
    "weights_stage3_hard = '../models/FLD_full/FLD_full_models/stage3_hard.caffemodel'\n",
    "assert(os.path.exists(weights_stage3_hard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# caffe prepare\n",
    "caffe.set_mode_gpu()\n",
    "caffe.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create net and load weights\n",
    "net_stage1 = caffe.Net(model_stage1, weights_stage1, caffe.TEST)\n",
    "# display([(k, v.data.shape) for k, v in net_stage1.blobs.items()])\n",
    "\n",
    "net_stage2 = caffe.Net(model_stage2, weights_stage2, caffe.TEST)\n",
    "# display([(k, v.data.shape) for k, v in net_stage2.blobs.items()])\n",
    "\n",
    "net_stage3_easy = caffe.Net(model_stage3, weights_stage3_easy, caffe.TEST)\n",
    "net_stage3_hard = caffe.Net(model_stage3, weights_stage3_hard, caffe.TEST)\n",
    "pipeline = {\n",
    "    'num_points': num_points,\n",
    "    'net_stage1': net_stage1,\n",
    "    'net_stage2': net_stage2,\n",
    "    'net_stage3_easy': net_stage3_easy,\n",
    "    'net_stage3_hard': net_stage3_hard\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '../data/FLD_full/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(img_path, display=True):\n",
    "    with open(img_path, 'rb') as f:\n",
    "        img = image.imdecode(f.read())\n",
    "    if display:\n",
    "        plt.imshow(img.asnumpy())\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_forword(img_orig: mx.ndarray.ndarray.NDArray, pipeline: dict):\n",
    "    \"\"\"\n",
    "    pipeline forward to make image processed\n",
    "    \"\"\"\n",
    "    # preprocess: image resize & pad\n",
    "    def get_padding_size(image):\n",
    "        h, w, _ = image.shape\n",
    "        longest_edge = max(h, w)\n",
    "        top, bottom, left, right = (0, 0, 0, 0)\n",
    "        if h < longest_edge:\n",
    "            dh = longest_edge - h\n",
    "            top = dh // 2\n",
    "            bottom = dh - top\n",
    "        elif w < longest_edge:\n",
    "            dw = longest_edge - w\n",
    "            left = dw // 2\n",
    "            right = dw - left\n",
    "        else:\n",
    "            pass\n",
    "        return top, bottom, left, right\n",
    "    scale = 224 / max(img_orig.shape)\n",
    "    s1 = round(img_orig.shape[0] * scale)\n",
    "    s2 = round(img_orig.shape[1] * scale)\n",
    "    if img_orig.shape[0] == 224 and img_orig.shape[1] == 224:\n",
    "        img_resi = img_orig.asnumpy()\n",
    "    else:\n",
    "        # https://www.programcreek.com/python/example/86048/cv2.copyMakeBorder\n",
    "        img_resi = cv2.resize(img_orig.asnumpy(), (s1,s2))\n",
    "        top, bottom, left, right = get_padding_size(img_resi)\n",
    "        BLACK = [0, 0, 0]\n",
    "        constant = cv2.copyMakeBorder(img_resi, top , bottom, left, right, cv2.BORDER_CONSTANT, value=BLACK)\n",
    "        img_resi = cv2.resize(constant, (224, 224))\n",
    "    \n",
    "    offset = np.array([0,0,0])\n",
    "    assert(img_resi.shape[0] == 224)\n",
    "    assert(img_resi.shape[1] == 224)\n",
    "    \n",
    "    def get_orig_coordinate(p):\n",
    "        \"\"\"\n",
    "        calculate location.\n",
    "        \"\"\"\n",
    "        value = (p + 0.5) * 224\n",
    "        return ( value - np.tile(np.array([offset[1], offset[0]]).T.reshape(-1, 1), (pipeline['num_points'],1)) \\\n",
    "                .reshape(value.shape) ) / scale\n",
    "    \n",
    "    # image normalization\n",
    "    img_stan = img_resi.astype('float32')\n",
    "    # normaliziation, refer to https://stackoverflow.com/questions/27970134/what-is-an-equivalent-of-matlab-permutea-3-2-1-in-python\n",
    "    img_stan = np.transpose(img_stan, (1,0,2))\n",
    "    img_stan = np.transpose(img_stan, (2,1,0))\n",
    "    \n",
    "    visibility_case = np.array(['Visible','Occlude','Inexistent'])\n",
    "    \n",
    "    # stage 1 fp\n",
    "    res_stage1 = pipeline['net_stage1'].forward(**{\n",
    "        pipeline['net_stage1'].inputs[0]: np.asarray([img_stan]) \n",
    "    })\n",
    "    landmark_stage1 = res_stage1['fc8'][:, 0:pipeline['num_points']*2]\n",
    "    landmark_stage1_values = res_stage1['fc8'][:, pipeline['num_points']*2:].reshape((3,pipeline['num_points']))\n",
    "    v1 = np.argmax(landmark_stage1_values, axis=0)\n",
    "    visibility_stage1 = visibility_case[v1]\n",
    "    \n",
    "    prediction_stage1 = {\n",
    "        'landmark': landmark_stage1, #get_orig_coordinate(landmark_stage1),\n",
    "        'visibility': visibility_stage1\n",
    "    };\n",
    "    \n",
    "    # stage 2 fp   \n",
    "    res_stage2 = pipeline['net_stage2'].forward(**{\n",
    "        pipeline['net_stage2'].inputs[0]: np.asarray([img_stan]), \n",
    "        pipeline['net_stage2'].inputs[1]: np.asarray([landmark_stage1])\n",
    "    });\n",
    "    landmark_stage2 = landmark_stage1 - res_stage2['fc8'][:, :pipeline['num_points']*2] / 5;\n",
    "    landmark_stage2_values = res_stage1['fc8'][:, pipeline['num_points']*2:].reshape((3, pipeline['num_points']))\n",
    "    \n",
    "    v2 = np.argmax(landmark_stage2_values, axis=0)\n",
    "    visibility_stage2 = visibility_case[v2]\n",
    "    \n",
    "    prediction_stage2 = {\n",
    "        'landmark': landmark_stage2, #get_orig_coordinate(landmark_stage2), \n",
    "        'visibility': visibility_stage2\n",
    "    };\n",
    "    \n",
    "    # stage 3 fp\n",
    "    res_stage3_easy = pipeline['net_stage3_easy'].forward(**{\n",
    "        pipeline['net_stage2'].inputs[0]: np.asarray([img_stan]), \n",
    "        pipeline['net_stage2'].inputs[1]: np.asarray([landmark_stage2])\n",
    "    });\n",
    "    res_stage3_hard = pipeline['net_stage3_hard'].forward(**{\n",
    "        pipeline['net_stage2'].inputs[0]: np.asarray([img_stan]), \n",
    "        pipeline['net_stage2'].inputs[1]: np.asarray([landmark_stage2])\n",
    "    });\n",
    "    landmark_stage3 = landmark_stage2 - (res_stage3_easy['fc8'][:, 0:pipeline['num_points']*2] /5  \n",
    "                                         + res_stage3_hard['fc8'][:, 0:pipeline['num_points']*2]/5) /2\n",
    "    \n",
    "    landmark_stage3_easy_values = res_stage3_easy['fc8'][:, pipeline['num_points']*2:] \\\n",
    "            .reshape((3, pipeline['num_points']))\n",
    "    landmark_stage3_hard_values = res_stage3_hard['fc8'][:, pipeline['num_points']*2:] \\\n",
    "            .reshape((3, pipeline['num_points']))\n",
    "\n",
    "    v3 = np.argmax(landmark_stage3_easy_values + landmark_stage3_hard_values, axis=0)\n",
    "    visibility_stage3 = visibility_case[v3]\n",
    "\n",
    "    prediction_stage3 = {\n",
    "        'landmark': landmark_stage3,#get_orig_coordinate(landmark_stage3),\n",
    "        'visibility': visibility_stage3\n",
    "    };\n",
    "    \n",
    "    # output\n",
    "    prediction = {\n",
    "        'stage1': prediction_stage1,\n",
    "        'stage2': prediction_stage2,\n",
    "        'stage3': prediction_stage3,\n",
    "        'num_points': pipeline['num_points']\n",
    "    }\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standize_image(img_path):\n",
    "    with open(img_path, 'rb') as f:\n",
    "        img = image.imdecode(f.read())\n",
    "    img_resi = cv2.resize(img.asnumpy(), (224, 224))\n",
    "    # image normalization\n",
    "    img_stan = img_resi.astype('float32')\n",
    "    # normaliziation, refer to https://stackoverflow.com/questions/27970134/what-is-an-equivalent-of-matlab-permutea-3-2-1-in-python\n",
    "    img_stan = np.transpose(img_stan, (1,0,2))\n",
    "    img_stan = np.transpose(img_stan, (2,1,0))\n",
    "    return img_stan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_batch_process(img_stan: [], pipeline: dict):\n",
    "    \"\"\"\n",
    "    pipeline forward to make image processed\n",
    "    \"\"\"\n",
    "    visibility_case = np.array(['Visible','Occlude','Inexistent'])\n",
    "    \n",
    "    # stage 1 fp\n",
    "    res_stage1 = pipeline['net_stage1'].forward(**{\n",
    "        pipeline['net_stage1'].inputs[0]: np.asarray(img_stan) \n",
    "    })\n",
    "    landmark_stage1 = res_stage1['fc8'][:, 0:pipeline['num_points']*2]\n",
    "    landmark_stage1_values = res_stage1['fc8'][:, pipeline['num_points']*2:].reshape((3,pipeline['num_points']))\n",
    "    v1 = np.argmax(landmark_stage1_values, axis=0)\n",
    "    visibility_stage1 = visibility_case[v1]\n",
    "    \n",
    "    prediction_stage1 = {\n",
    "        'landmark': get_orig_coordinate(landmark_stage1),\n",
    "        'visibility': visibility_stage1\n",
    "    };\n",
    "    \n",
    "    # stage 2 fp   \n",
    "    res_stage2 = pipeline['net_stage2'].forward(**{\n",
    "        pipeline['net_stage2'].inputs[0]: np.asarray([img_stan]), \n",
    "        pipeline['net_stage2'].inputs[1]: np.asarray([landmark_stage1])\n",
    "    });\n",
    "    landmark_stage2 = landmark_stage1 - res_stage2['fc8'][:, :pipeline['num_points']*2] / 5;\n",
    "    landmark_stage2_values = res_stage1['fc8'][:, pipeline['num_points']*2:].reshape((3, pipeline['num_points']))\n",
    "    \n",
    "    v2 = np.argmax(landmark_stage2_values, axis=0)\n",
    "    visibility_stage2 = visibility_case[v2]\n",
    "    \n",
    "    prediction_stage2 = {\n",
    "        'landmark': get_orig_coordinate(landmark_stage2),\n",
    "        'visibility': visibility_stage2\n",
    "    };\n",
    "    \n",
    "    # stage 3 fp\n",
    "    res_stage3_easy = pipeline['net_stage3_easy'].forward(**{\n",
    "        pipeline['net_stage2'].inputs[0]: np.asarray([img_stan]), \n",
    "        pipeline['net_stage2'].inputs[1]: np.asarray([landmark_stage2])\n",
    "    });\n",
    "    res_stage3_hard = pipeline['net_stage3_hard'].forward(**{\n",
    "        pipeline['net_stage2'].inputs[0]: np.asarray([img_stan]), \n",
    "        pipeline['net_stage2'].inputs[1]: np.asarray([landmark_stage2])\n",
    "    });\n",
    "    landmark_stage3 = landmark_stage2 - (res_stage3_easy['fc8'][:, 0:pipeline['num_points']*2] /5  \n",
    "                                         + res_stage3_hard['fc8'][:, 0:pipeline['num_points']*2]/5) /2\n",
    "    \n",
    "    landmark_stage3_easy_values = res_stage3_easy['fc8'][:, pipeline['num_points']*2:] \\\n",
    "            .reshape((3, pipeline['num_points']))\n",
    "    landmark_stage3_hard_values = res_stage3_hard['fc8'][:, pipeline['num_points']*2:] \\\n",
    "            .reshape((3, pipeline['num_points']))\n",
    "\n",
    "    v3 = np.argmax(landmark_stage3_easy_values + landmark_stage3_hard_values, axis=0)\n",
    "    visibility_stage3 = visibility_case[v3]\n",
    "\n",
    "    prediction_stage3 = {\n",
    "        'landmark': get_orig_coordinate(landmark_stage3),\n",
    "        'visibility': visibility_stage3\n",
    "    };\n",
    "    \n",
    "    # output\n",
    "    prediction = {\n",
    "        'stage1': prediction_stage1,\n",
    "        'stage2': prediction_stage2,\n",
    "        'stage3': prediction_stage3,\n",
    "        'num_points': pipeline['num_points']\n",
    "    }\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(img, prediction):\n",
    "    \"\"\"\n",
    "    display landmark in picture.\n",
    "    \"\"\"\n",
    "    plt.imshow(img.asnumpy())\n",
    "    visibility_case = np.array(['Visible', 'Occlude', 'Inexistent'])\n",
    "    colors = np.array(['y','b','g'])\n",
    "    for c in range(3):\n",
    "        pairs = prediction['stage1']['landmark'].reshape(-1, 2)\\\n",
    "            [np.where(prediction['stage1']['visibility'] == visibility_case[c])]\n",
    "        plt.plot(pairs[:, 0], pairs[:, 1], marker='s', color=colors[c], ls='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network processing\n",
    "# http://caffe.berkeleyvision.org/tutorial/interfaces.html\n",
    "# http://christopher5106.github.io/deep/learning/2015/09/04/Deep-learning-tutorial-on-Caffe-Technology.html\n",
    "files = [os.path.join(image_path, f) for f in os.listdir(image_path) if os.path.isfile(os.path.join(image_path, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network processing\n",
    "# http://caffe.berkeleyvision.org/tutorial/interfaces.html\n",
    "# http://christopher5106.github.io/deep/learning/2015/09/04/Deep-learning-tutorial-on-Caffe-Technology.html\n",
    "image_path = '../../FashionAI-Attributes/data/web/Images/skirt_length_labels'\n",
    "files = [os.path.join(image_path, f) for f in os.listdir(image_path) if os.path.isfile(os.path.join(image_path, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_single_process(tuple_data):\n",
    "    \"\"\"\n",
    "    pipeline forward to make image processed\n",
    "    \"\"\"\n",
    "    i, img_stan = tuple_data\n",
    "    visibility_case = np.array(['Visible','Occlude','Inexistent'])\n",
    "    \n",
    "    # stage 1 fp\n",
    "    res_stage1 = pipeline['net_stage1'].forward(**{\n",
    "        pipeline['net_stage1'].inputs[0]: np.asarray([img_stan]) \n",
    "    })\n",
    "    landmark_stage1 = res_stage1['fc8'][:, 0:pipeline['num_points']*2]\n",
    "    landmark_stage1_values = res_stage1['fc8'][:, pipeline['num_points']*2:].reshape((3,pipeline['num_points']))\n",
    "    v1 = np.argmax(landmark_stage1_values, axis=0)\n",
    "    visibility_stage1 = visibility_case[v1]\n",
    "    \n",
    "    prediction_stage1 = {\n",
    "        'landmark': res_stage1, #get_orig_coordinate(landmark_stage1),\n",
    "        'visibility': visibility_stage1\n",
    "    };\n",
    "    \n",
    "    # stage 2 fp   \n",
    "    res_stage2 = pipeline['net_stage2'].forward(**{\n",
    "        pipeline['net_stage2'].inputs[0]: np.asarray([img_stan]), \n",
    "        pipeline['net_stage2'].inputs[1]: np.asarray([landmark_stage1])\n",
    "    });\n",
    "    landmark_stage2 = landmark_stage1 - res_stage2['fc8'][:, :pipeline['num_points']*2] / 5;\n",
    "    landmark_stage2_values = res_stage1['fc8'][:, pipeline['num_points']*2:].reshape((3, pipeline['num_points']))\n",
    "    \n",
    "    v2 = np.argmax(landmark_stage2_values, axis=0)\n",
    "    visibility_stage2 = visibility_case[v2]\n",
    "    \n",
    "    prediction_stage2 = {\n",
    "        'landmark': landmark_stage2, #get_orig_coordinate(landmark_stage2),\n",
    "        'visibility': visibility_stage2\n",
    "    };\n",
    "    \n",
    "    # stage 3 fp\n",
    "    res_stage3_easy = pipeline['net_stage3_easy'].forward(**{\n",
    "        pipeline['net_stage2'].inputs[0]: np.asarray([img_stan]), \n",
    "        pipeline['net_stage2'].inputs[1]: np.asarray([landmark_stage2])\n",
    "    });\n",
    "    res_stage3_hard = pipeline['net_stage3_hard'].forward(**{\n",
    "        pipeline['net_stage2'].inputs[0]: np.asarray([img_stan]), \n",
    "        pipeline['net_stage2'].inputs[1]: np.asarray([landmark_stage2])\n",
    "    });\n",
    "    landmark_stage3 = landmark_stage2 - (res_stage3_easy['fc8'][:, 0:pipeline['num_points']*2] /5  \n",
    "                                         + res_stage3_hard['fc8'][:, 0:pipeline['num_points']*2]/5) /2\n",
    "    \n",
    "    landmark_stage3_easy_values = res_stage3_easy['fc8'][:, pipeline['num_points']*2:] \\\n",
    "            .reshape((3, pipeline['num_points']))\n",
    "    landmark_stage3_hard_values = res_stage3_hard['fc8'][:, pipeline['num_points']*2:] \\\n",
    "            .reshape((3, pipeline['num_points']))\n",
    "\n",
    "    v3 = np.argmax(landmark_stage3_easy_values + landmark_stage3_hard_values, axis=0)\n",
    "    visibility_stage3 = visibility_case[v3]\n",
    "\n",
    "    prediction_stage3 = {\n",
    "        'landmark': landmark_stage3, #get_orig_coordinate(landmark_stage3),\n",
    "        'visibility': visibility_stage3\n",
    "    };\n",
    "    \n",
    "    # output\n",
    "    prediction = {\n",
    "        'stage1': prediction_stage1,\n",
    "        'stage2': prediction_stage2,\n",
    "        'stage3': prediction_stage3,\n",
    "        'num_points': pipeline['num_points']\n",
    "    }\n",
    "    \n",
    "    return i, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 632/10110 [19:57<4:59:25,  1.90s/it]"
     ]
    }
   ],
   "source": [
    "# multiprocessing for loading image\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import multiprocessing\n",
    "\n",
    "n = len(files)\n",
    "results = {}\n",
    "\n",
    "with multiprocessing.Pool(12) as pool:\n",
    "    # merge parameter as tuple\n",
    "    args = [(i, standize_image(files[i])) for i in range(n)]\n",
    "    with tqdm(pool.imap_unordered(pipeline_single_process, args), total=n) as pbar:\n",
    "        for i, prediction in pbar:\n",
    "            results[i] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction = pipeline_batch_process(imgs, pipeline)\n",
    "# show_results(img_orig, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
